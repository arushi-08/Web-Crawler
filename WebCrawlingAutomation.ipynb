{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NONev1vMiYwZ"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pickle\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pdfkit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Webcrawling:\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.mfr=mfr\n",
    "        self.datasheet=datasheet\n",
    "        self.start_index=start_index\n",
    "        self.end_index=end_index\n",
    "\n",
    "    def splitDFIntoSmalldf(self,df):\n",
    "        chunkSize = 20\n",
    "        listOfDf = []\n",
    "        numberChunks = len(df) // chunkSize + 1\n",
    "        for i in range(numberChunks):\n",
    "            listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "        return listOfDf\n",
    "\n",
    "\n",
    "    def launchBrowser(self):    \n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        prefs={\"profile.managed_default_content_settings.images\": 2, 'disk-cache-size': 4096 }\n",
    "        chromeOptions.add_experimental_option('prefs', prefs)\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options = chromeOptions)\n",
    "        driver.get(mfr)\n",
    "        return driver    \n",
    "    \n",
    "    \n",
    "    def maxim(self):\n",
    "        df = pd.read_excel(datasheet)\n",
    "        df.columns = ['PTNO','LINK'] \n",
    "        df_list = self.splitDFIntoSmalldf(df[int(start_index):int(end_index)])\n",
    "        print(df_list)\n",
    "        driver = self.launchBrowser()\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        under_score = ['/','?', '<', '>', '\\\\', ':', '*', '|', '\"', ]\n",
    "\n",
    "        for dataframe_no in range(len(df_list)):\n",
    "            if (dataframe_no)%5==0:\n",
    "                time.sleep(3)\n",
    "                driver.get(\"https://www.maximintegrated.com/en/emmi/content_lookup.cfm?Ac=S\")\n",
    "\n",
    "            print('DataFrame Number: ', dataframe_no)\n",
    "            url_list=[]\n",
    "            for i,count in zip(df_list[dataframe_no]['PTNO'],range(len(df_list[dataframe_no]['PTNO']))):\n",
    "# find Part input field\n",
    "                try:\n",
    "                    id_box = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"input[name='pn']\")))\n",
    "                    time.sleep(4)\n",
    "                except:\n",
    "                    time.sleep(4)\n",
    "                    driver.get(\"https://www.maximintegrated.com/en/emmi/content_lookup.cfm?Ac=S\")            \n",
    "                    id_box = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"input[name='pn']\")))\n",
    "\n",
    "\n",
    "                id_box.clear()\n",
    "                id_box.send_keys(i)\n",
    "# Find submit button\n",
    "                login_button = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"input[type='submit']\"))).click()\n",
    "\n",
    "                base = driver.window_handles[0]                \n",
    "\n",
    "                try:\n",
    "                    noOfRows = len(WebDriverWait(driver, 6).until(EC.presence_of_all_elements_located((By.XPATH,'/html/body/div/div[1]/div[2]/div[2]/table/tbody/tr/td/div[5]/table/tbody/tr'))))\n",
    "                except:\n",
    "                    noOfRows=0\n",
    "                if noOfRows>0:\n",
    "                    for row in range(noOfRows):\n",
    "                        cell=WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.XPATH,'/html/body/div/div[1]/div[2]/div[2]/table/tbody/tr/td/div[5]/table/tbody/tr['+str(row+2)+']/td[1]/a'))).text\n",
    "                        if cell == i:\n",
    "                            print(cell)\n",
    "                            check=1\n",
    "                            WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.XPATH,'/html/body/div/div[1]/div[2]/div[2]/table/tbody/tr/td/div[5]/table/tbody/tr['+str(row+2)+']/td[1]/a'))).click()\n",
    "                        break\n",
    "                    if check==0:\n",
    "                        print(count)\n",
    "                        print('Part not found')\n",
    "                        url_list.append('')\n",
    "                        break\n",
    "\n",
    "                if len(url_list)==count:\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"divContent\"]/table/tbody/tr/td/table/tbody/tr[2]/td/a'))).click()\n",
    "                        handles = driver.window_handles\n",
    "                        driver.implicitly_wait(3)\n",
    "                        driver.switch_to_window(handles[1])\n",
    "                        driver.implicitly_wait(10)\n",
    "                        print(count)\n",
    "                        url_list.append(driver.current_url)\n",
    "                        print(driver.current_url)\n",
    "                        driver.implicitly_wait(2)\n",
    "\n",
    "                        driver.close()\n",
    "                        driver.switch_to_window (base)\n",
    "                        \n",
    "                    except:\n",
    "                        print(count)\n",
    "                        print(\"Part/PDF not found\")\n",
    "                        url_list.append(\"\")\n",
    "                        driver.implicitly_wait(4)\n",
    "\n",
    "                try:\n",
    "                    driver.back()\n",
    "                except:\n",
    "                    time.sleep(3)\n",
    "                    driver.get(\"https://www.maximintegrated.com/en/emmi/content_lookup.cfm?Ac=S\")\n",
    "                    driver.implicitly_wait(10)\n",
    "\n",
    "                while len(url_list)-count!=1:\n",
    "                    url_list.pop()\n",
    "            print(url_list)\n",
    "            df_list[dataframe_no]['LINK'] = pd.Series(url_list).values\n",
    "            print(df_list[dataframe_no])\n",
    "            for i,part in zip(url_list,df_list[dataframe_no]['PTNO']):\n",
    "                if len(i)!=0:\n",
    "                    r = requests.get(i)     # create HTTP response object \n",
    "                                            # send a HTTP request to the server and save \n",
    "                                            # the HTTP response in a response object called r\n",
    "                    for char in part:\n",
    "                        if (char in under_score): \n",
    "                            part = part.replace(char,'_')\n",
    "                    with open(r\"PDFs_downloads\\MXM\\ \"+str(part)+\".pdf\", \"wb\") as f:\n",
    "                        f.write(r.content)\n",
    "\n",
    "\n",
    "        df_mainlist = pd.concat(df_list)\n",
    "        df_mainlist.to_csv('PDFs_downloads\\MXM\\MXM_datasheet_'+str(start_index)+'.dat',sep='|',index=False)\n",
    "\n",
    "        driver.quit()\n",
    "        \n",
    "    def stmi(self):\n",
    "        df = pd.read_excel(datasheet)\n",
    "        df.columns = ['PTNO','LINK']\n",
    "\n",
    "        df_list = self.splitDFIntoSmalldf(df[int(start_index):int(end_index)])\n",
    "\n",
    "        driver = self.launchBrowser()\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.find_element_by_xpath('//*[@id=\"st-site\"]/div[1]/div[2]/div[4]/div[2]/div').click()\n",
    "\n",
    "\n",
    "        for dataframe_no in range(len(df_stmi)):\n",
    "            if (dataframe_no)%5==0:\n",
    "                time.sleep(3)\n",
    "                driver.get(\"https://www.st.com/content/st_com/en.html\")\n",
    "\n",
    "            print('DataFrame Number: ', dataframe_no)\n",
    "            url_list_2=[]\n",
    "            for i,count in zip(df_list[dataframe_no]['PTNO'],range(len(df_list[dataframe_no]['PTNO']))):\n",
    "\n",
    "                driver.implicitly_wait(3)\n",
    "                try:\n",
    "                    id_box = driver.find_element_by_css_selector(\"input[id='widgetSearchBar']\")\n",
    "\n",
    "                except:\n",
    "                    time.sleep(4)\n",
    "                    driver.get(\"https://www.st.com/content/st_com/en.html\")    \n",
    "                    driver.implicitly_wait(3)\n",
    "                    id_box = driver.find_element_by_css_selector(\"input[id='widgetSearchBar']\")\n",
    "\n",
    "\n",
    "                id_box.clear()\n",
    "                id_box.send_keys(i)\n",
    "                \n",
    "                driver.find_element_by_link_text(\"Search\").click()\n",
    "                driver.implicitly_wait(30)\n",
    "\n",
    "                userName=driver.find_element_by_xpath('//*[@id=\"searchKey\"]')\n",
    "                driver.execute_script(\"arguments[0].click();\", userName)\n",
    "                driver.implicitly_wait(20)\n",
    "                driver.find_element_by_xpath('//*[@id=\"search-table-products\"]/tbody/tr/td[1]/a').click()\n",
    "                driver.implicitly_wait(10)\n",
    "                driver.find_element_by_xpath('//*[@id=\"st-site\"]/div[6]/div[1]/main/div[1]/div[3]/div/div/div[1]/div[2]/div/div[4]/div/span').click()\n",
    "                driver.implicitly_wait(30)     \n",
    "                \n",
    "\n",
    "                noOfRows = len(driver.find_elements_by_xpath('//*[@id=\"st-site\"]/div[6]/div[1]/main/div[1]/div[4]/div[4]/div/div/div[1]/div[1]/table/tbody/tr'))\n",
    "                try:\n",
    "                    for row in range(noOfRows):\n",
    "                        cell=driver.find_element_by_xpath('//*[@id=\"st-site\"]/div[6]/div[1]/main/div[1]/div[4]/div[4]/div/div/div[1]/div[1]/table/tbody/tr['+str(row+1)+']/td[1]').text\n",
    "                        if cell == i:\n",
    "                            print(count)\n",
    "                            driver.find_element_by_xpath('//*[@id=\"st-site\"]/div[6]/div[1]/main/div[1]/div[4]/div[4]/div/div/div[1]/div[1]/table/tbody/tr['+str(row+1)+']/td[5]/div/a[1]').click()\n",
    "                            driver.implicitly_wait(8)\n",
    "                            url_list_2.append(driver.current_url)\n",
    "                            print(driver.current_url)\n",
    "                            driver.back()\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(count)\n",
    "                    time.sleep(3)\n",
    "                    driver.get(\"https://www.st.com/content/st_com/en.html\")\n",
    "                    url_list_2.append(\"\")\n",
    "                    driver.implicitly_wait(10)\n",
    "\n",
    "                except:\n",
    "                    print(count)\n",
    "                    print('Pdf not found')\n",
    "                    url_list_2.append('')\n",
    "\n",
    "                driver.implicitly_wait(3)  \n",
    "\n",
    "            df_stmi[dataframe_no]['LINK'] = pd.Series(url_list_2).values\n",
    "\n",
    "            for i,part in zip(url_list_2,df_list[dataframe_no]['PTNO']):\n",
    "                if len(i)!=0:\n",
    "                    r = requests.get(i)\n",
    "                    for char in part:\n",
    "                                if (char in under_score): \n",
    "                                    part = part.replace(char,'_')\n",
    "                    with open(r\"PDFs_downloads\\STMI\\ \"+str(part)+\".pdf\", \"wb\") as f:\n",
    "                        f.write(r.content) \n",
    "\n",
    "        df_mainlist = pd.concat(df_list)\n",
    "        df_mainlist.to_csv('PDFs_downloads\\STMI\\STMI_datasheet_'+str(start_index)+'.dat',sep='|',index=False)\n",
    "        driver.quit()\n",
    "        \n",
    "    def cui(self):\n",
    "        df = pd.read_excel(datasheet)\n",
    "        df.columns = ['PART_NUMBER','LINK']\n",
    "        df_list = self.splitDFIntoSmalldf(df[int(start_index):int(end_index)])\n",
    "        driver = self.launchBrowser()\n",
    "        driver.maximize_window()\n",
    "\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        url_list_final = []\n",
    "        under_score = ['/','?', '<', '>', '\\\\', ':', '*', '|', '\"', ]\n",
    "\n",
    "        for dataframe_no in range(len(df_list)):\n",
    "            if (dataframe_no)%5==0:\n",
    "                time.sleep(3)\n",
    "                driver.get(\"https://www.cui.com/\")\n",
    "\n",
    "            print('DataFrame Number: ', dataframe_no)\n",
    "            url_list=[]\n",
    "            for i,count in zip(df_list[dataframe_no]['PART_NUMBER'],range(len(df_list[dataframe_no]['PART_NUMBER']))):\n",
    "                try:\n",
    "                    id_box = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/div[1]/form/input[1]')))\n",
    "                except:\n",
    "                    time.sleep(4)\n",
    "                    driver.get(\"https://www.cui.com/\")            \n",
    "                    id_box = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/div[1]/form/input[1]')))\n",
    "                id_box.clear()\n",
    "                id_box.send_keys(i)\n",
    "                # Find submit button\n",
    "                login_button = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"input[type='Submit']\"))).click()\n",
    "\n",
    "                base = driver.window_handles[0]   \n",
    "\n",
    "\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"a[rel='nofollow'][href*='material-compliance']\"))).click()\n",
    "                    handles = driver.window_handles\n",
    "                    driver.implicitly_wait(5)\n",
    "                    driver.switch_to_window(handles[1])\n",
    "                    driver.implicitly_wait(10)\n",
    "                    print(count)\n",
    "                    url_list.append(driver.current_url)\n",
    "                    print(driver.current_url)\n",
    "                    driver.implicitly_wait(2)\n",
    "\n",
    "                    driver.close()\n",
    "                    driver.switch_to_window (base)\n",
    "\n",
    "                except:\n",
    "                    print(count)\n",
    "                    print(\"Part/PDF not found\")\n",
    "                    url_list.append('')   \n",
    "                  \n",
    "                try:\n",
    "                    driver.back()\n",
    "\n",
    "                except TimeoutException:\n",
    "                    time.sleep(3)\n",
    "                    driver.get(\"https://www.cui.com/\")\n",
    "                    driver.implicitly_wait(10)\n",
    "\n",
    "            df_list[dataframe_no]['LINK'] = pd.Series(url_list).values\n",
    "            for i,part in zip(url_list, df_list[dataframe_no]['PART_NUMBER']):\n",
    "                if i:\n",
    "                    pdfkit.from_url(i, \"PDFs_downloads\\CUI\\ \"+str(part)+\".pdf\")\n",
    "\n",
    "            url_list_final.append(url_list)\n",
    "\n",
    "        driver.quit()\n",
    "        df_mainlist = pd.concat(df_list)\n",
    "        df_mainlist.to_csv('PDFs_downloads\\CUI\\CUI_datasheet_'+str(start_index)+'.dat',sep='|',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evrqBrWKiYwc",
    "outputId": "6a3f415e-96e7-4bb8-f572-90e3392cc27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Manufacturer Website: https://www.cui.com/\n",
      "Enter Datasheet Path: C:\\Users\\arushi.sharma\\Documents\\WebCrawling\\CUI.xlsx\n",
      "Enter Starting Row: 4\n",
      "Enter Ending Row: 6\n",
      "\n",
      "Checking for win32 chromedriver:75.0.3770.140 in cache\n",
      "Driver found in C:\\Users\\arushi.sharma\\.wdm\\chromedriver\\75.0.3770.140\\win32/chromedriver.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arushi.sharma\\appdata\\local\\programs\\python37\\myenv\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Number:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arushi.sharma\\appdata\\local\\programs\\python37\\myenv\\lib\\site-packages\\ipykernel_launcher.py:273: DeprecationWarning: use driver.switch_to.window instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://www.cui.com/product/resource/material-compliance/mj1-2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arushi.sharma\\appdata\\local\\programs\\python37\\myenv\\lib\\site-packages\\ipykernel_launcher.py:281: DeprecationWarning: use driver.switch_to.window instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Part/PDF not found\n",
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    mfr=input('Enter Manufacturer Website: ')\n",
    "    datasheet=input('Enter Datasheet Path: ')\n",
    "    start_index = input('Enter Starting Row: ')\n",
    "    end_index = input('Enter Ending Row: ')\n",
    "\n",
    "    webcrawl = Webcrawling()\n",
    "    if mfr==\"https://www.maximintegrated.com/en/emmi/content_lookup.cfm?Ac=S\":\n",
    "        webcrawl.maxim()\n",
    "    if mfr==\"https://www.st.com/content/st_com/en.html\":\n",
    "        webcrawl.stmi()\n",
    "    if mfr==\"https://www.cui.com/\":    \n",
    "        webcrawl.cui()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "WebCrawlingAutomation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
